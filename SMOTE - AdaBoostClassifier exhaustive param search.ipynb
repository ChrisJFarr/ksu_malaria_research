{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Feature Importance for Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process steps:\n",
    "* Build full dataset with decoys and compounds\n",
    "* Build compound-only dataset\n",
    "* Preprocess categorical with one-hot-encoding\n",
    "* Find intersecting columns and filter compound-only to these\n",
    "* Add non-linear transformations to compound-only dataset\n",
    "* Create binary target with IC50 <= 10 as 1, else 0\n",
    "* Using compound-only df, fine-tune random forest with GridSearchCV (CV = count of positive class)\n",
    "* Extract feature importance and remove any with importance of 0\n",
    "* Create important features in full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skewtest\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from custom_functions import *\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools as it\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_transformations = [\"log\", \"log2\", \"log10\", \"cubert\", \n",
    "                         \"sqrt\", \"exp\", \"exp2\", \"cube\", \"sq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build full-dataset\n",
    "* Build compound-dataset\n",
    "* Preprocess data adding one-hot-encoded features for both\n",
    "* Find intersecting columns\n",
    "* Add non-linear transformations and drop na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Akt1_decoys_padel.csv....\n",
      "Adding AmpC_decoys_padel.csv....\n",
      "Adding cp3a4_decoys_padel.csv....\n",
      "Adding cxcr4_decoys_padel.csv....\n",
      "Adding gcr_decoys_padel.csv....\n",
      "Adding HIVpr_decoys_padel.csv....\n",
      "Adding HIVrt_decoys_padel.csv....\n",
      "Adding Kif11_decoys_padel.csv....\n",
      "Loading in compound dataset....\n",
      "Adding non-linear features to compound dataset....\n"
     ]
    }
   ],
   "source": [
    "# Load in full dataset\n",
    "full_x, full_y = load_full_dataset()\n",
    "# Preprocess variables\n",
    "full_x = preprocess_variables(full_x)\n",
    "# Extract list of available columns\n",
    "full_columns = full_x.columns\n",
    "print(\"Loading in compound dataset....\")\n",
    "# Read in compound dataset\n",
    "compound_x, compound_y = load_compound_dataset()\n",
    "# Preprocess\n",
    "compound_x = preprocess_variables(compound_x)\n",
    "# Find intersecting features\n",
    "avail_columns = compound_x.columns.intersection(full_columns)\n",
    "# Select features on subset\n",
    "x_data = compound_x.loc[:, avail_columns]\n",
    "y_data = compound_y.copy()\n",
    "print(\"Adding non-linear features to compound dataset....\")\n",
    "# Add all transformations on compound data\n",
    "for feature in x_data.columns[x_data.dtypes == 'float64']:\n",
    "    x_data = add_transformations(x_data, feature)\n",
    "# Drop any new columns with NaN due to improper transformation\n",
    "x_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "x_data.dropna(axis=1, inplace=True)\n",
    "assert not sum(x_data.isna().sum()), \"Unexpected nulls found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary variable\n",
    "y_class = np.squeeze([int(y_val <= 10) for y_val in y_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive Hyperparameter Tuning\n",
    "* SMOTE and resampling transformations on train only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:\n",
      "{'a_SMOTE_k_neighbors': 4, 'b_SMOTE_m_neighbors': 10, 'c_model_n_estimators': 50, 'd_model_learning_rate': 0.05, 'downsample': False, 'smote': True}\n",
      "Best Score:\n",
      "0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Search for best params with SMOTE on train\n",
    "params = {\"a_SMOTE_k_neighbors\": [3, 4],\n",
    "          \"b_SMOTE_m_neighbors\": [10],\n",
    "          \"c_model_n_estimators\": [40, 50, 60],\n",
    "          \"d_model_learning_rate\": [0.05],\n",
    "          \"smote\": [True],\n",
    "          \"downsample\": [False, 1, 3]}  # Bigger=>less downsampling\n",
    "all_names = sorted(params)  # TODO remove sorted but ensure correct order\n",
    "combinations = it.product(*(params[Name] for Name in all_names))\n",
    "\n",
    "# Initialize params\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for param_values in combinations:\n",
    "    param_dict = dict(zip(all_names, param_values))\n",
    "\n",
    "    model = AdaBoostClassifier(random_state=0, \n",
    "                               learning_rate=param_dict.get(\"d_model_learning_rate\"),\n",
    "                               n_estimators=param_dict.get(\"c_model_n_estimators\"))\n",
    "    smote = SMOTE(random_state=0, k_neighbors=param_dict.get(\"a_SMOTE_k_neighbors\"),\n",
    "                  m_neighbors=param_dict.get(\"b_SMOTE_m_neighbors\"))\n",
    "    kfold = StratifiedKFold(n_splits=sum(y_class), shuffle=True, random_state=0)\n",
    "    prediction_df = pd.DataFrame(columns=[\"prediction\"])\n",
    "    scores = []\n",
    "    for train, test in kfold.split(x_data, y_class):\n",
    "        # Split into train/test\n",
    "        x_train, y_train = x_data.iloc[train], y_class[train]\n",
    "        x_test, y_test = x_data.iloc[test], y_class[test]\n",
    "        assert sum(y_test) == 1, \"Ensure only one positive class is in test per iteration\"\n",
    "        # Perform SMOTE transformation on train\n",
    "        if param_dict.get(\"smote\"):\n",
    "            x_train, y_train = smote.fit_sample(x_train, y_train)\n",
    "        # Downsample randomly\n",
    "        if param_dict.get(\"downsample\"):\n",
    "            negative_n = len(y_train) - sum(y_train)\n",
    "            positive_n = sum(y_train)\n",
    "            balance = min(1, param_dict.get(\"downsample\") * (positive_n / negative_n))\n",
    "            negative_n *= balance\n",
    "            negative_n = int(negative_n)\n",
    "            down_sampler = RandomUnderSampler(ratio={0: negative_n, 1: positive_n}, random_state=0)\n",
    "            x_train, y_train = down_sampler.fit_sample(x_train, y_train)\n",
    "        model.fit(x_train, y_train)\n",
    "        prediction = model.predict(x_test)\n",
    "        # sample_weight = compute_sample_weight(\"balanced\", y_train)\n",
    "        scores.append(roc_auc_score(y_test, prediction))\n",
    "    # Calculate scores for parameters\n",
    "    params_score = np.mean(scores)\n",
    "    # Test new score against best\n",
    "    if params_score > best_score:\n",
    "        # Store the best\n",
    "        best_params = param_dict\n",
    "        best_score = params_score\n",
    "\n",
    "# Print the best params and score\n",
    "print(\"Best Params:\")\n",
    "print(best_params)\n",
    "print(\"Best Score:\")\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Params:\n",
    "{'a_SMOTE_k_neighbors': 2, 'b_SMOTE_m_neighbors': 9, 'c_model_n_estimators': 35, 'd_model_learning_rate': 0.075, 'downsample': False, 'smote': False}\n",
    "Best Score:\n",
    "0.7424242424242425"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement LOPOCV (leave one Positive out cross val)\n",
    "model = AdaBoostClassifier(random_state=0, \n",
    "                           learning_rate=param_dict.get(\"d_model_learning_rate\"),\n",
    "                           n_estimators=param_dict.get(\"c_model_n_estimators\"))\n",
    "smote = SMOTE(random_state=0, k_neighbors=param_dict.get(\"a_SMOTE_k_neighbors\"),\n",
    "              m_neighbors=param_dict.get(\"b_SMOTE_m_neighbors\"))\n",
    "kfold = StratifiedKFold(n_splits=sum(y_class), shuffle=True, random_state=0)\n",
    "prediction_df = pd.DataFrame(columns=[\"prediction\"])\n",
    "for train, test in kfold.split(x_data, y_class):\n",
    "    # Split into train/test\n",
    "    x_train, y_train = x_data.iloc[train], y_class[train]\n",
    "    x_test, y_test = x_data.iloc[test], y_class[test]\n",
    "    assert sum(y_test) == 1, \"Ensure only one positive class is in test per iteration\"\n",
    "    # Perform SMOTE transformation on train\n",
    "    if param_dict.get(\"smote\"):\n",
    "        x_train, y_train = smote.fit_sample(x_train, y_train)\n",
    "    # Downsample randomly\n",
    "    if param_dict.get(\"downsample\"):\n",
    "        negative_n = len(y_train) - sum(y_train)\n",
    "        positive_n = sum(y_train)\n",
    "        balance = min(1, param_dict.get(\"downsample\") * (positive_n / negative_n))\n",
    "        negative_n *= balance\n",
    "        negative_n = int(negative_n)\n",
    "        down_sampler = RandomUnderSampler(ratio={0: negative_n, 1: positive_n}, random_state=0)\n",
    "        x_train, y_train = down_sampler.fit_sample(x_train, y_train)\n",
    "    model.fit(x_train, y_train)\n",
    "    prediction = model.predict(x_test)\n",
    "    # sample_weight = compute_sample_weight(\"balanced\", y_train)\n",
    "    prediction = model.predict(x_test)\n",
    "    prediction_df = prediction_df.append(pd.DataFrame({\"prediction\": prediction}, index=test))\n",
    "    prediction_df.sort_index(inplace=True)\n",
    "    prediction_df = prediction_df.astype(int)\n",
    "# Calculate scores for parameters\n",
    "params_score = np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning AdaBoost on compound dataset....\n",
      "{'learning_rate': 0.05, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# How well does AdaBoost predict potency?\n",
    "print(\"Tuning AdaBoost on compound dataset....\")\n",
    "model = AdaBoostClassifier(random_state=0)\n",
    "params = {\"n_estimators\": [35, 40, 45],\n",
    "          \"learning_rate\": [0.05, 0.075]}\n",
    "grid = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=3)\n",
    "\n",
    "grid.fit(x_data, y_class)\n",
    "print(grid.best_params_)\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  5]\n",
      " [ 5 31]]\n",
      "[['TP' 'FN']\n",
      " ['FP' 'TN']]\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV prediction performance\n",
    "predict = cross_val_predict(\n",
    "    best_model, x_data, y_class, cv=sum(y_class), method=\"predict\")\n",
    "\n",
    "predict_proba = cross_val_predict(\n",
    "    best_model, x_data, y_class, cv=sum(y_class), method=\"predict_proba\")\n",
    "\n",
    "print(confusion_matrix(y_class, predict, labels=[1, 0]))\n",
    "print(np.array([[\"TP\", \"FN\"], [\"FP\", \"TN\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached https://files.pythonhosted.org/packages/80/a4/900463a3c0af082aed9c5a43f4ec317a9469710c5ef80496c9abc26ed0ca/imbalanced_learn-0.3.3-py3-none-any.whl\n",
      "Requirement not upgraded as not directly required: scikit-learn in c:\\miniconda3\\envs\\deep-learn\\lib\\site-packages (from imbalanced-learn) (0.19.1)\n",
      "Requirement not upgraded as not directly required: numpy in c:\\miniconda3\\envs\\deep-learn\\lib\\site-packages (from imbalanced-learn) (1.14.3)\n",
      "Requirement not upgraded as not directly required: scipy in c:\\miniconda3\\envs\\deep-learn\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.3.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow-tensorboard 1.5.1 has requirement bleach==1.5.0, but you'll have bleach 2.1.3 which is incompatible.\n",
      "tensorflow-tensorboard 1.5.1 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\n",
      "tensorboard 1.6.0 has requirement bleach==1.5.0, but you'll have bleach 2.1.3 which is incompatible.\n",
      "tensorboard 1.6.0 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost with SMOTE\n",
    "!pip install -U imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       IC50  y_class  Prediction     Proba\n",
      "0     0.036        1           1  0.999833\n",
      "1    10.000        1           1  0.020414\n",
      "2    50.000        0           0  0.012971\n",
      "3    50.000        0           0  0.938043\n",
      "4    50.000        0           0  0.012011\n",
      "5     8.000        1           1  0.999862\n",
      "6    50.000        0           0  0.012011\n",
      "7    50.000        0           0  0.020414\n",
      "8    35.000        0           0  0.020414\n",
      "9    50.000        0           0  0.024974\n",
      "10   45.000        0           0  0.020414\n",
      "11   45.000        0           0  0.990988\n",
      "12   40.000        0           0  0.011972\n",
      "13   50.000        0           0  0.011972\n",
      "14   50.000        0           0  0.011972\n",
      "15   50.000        0           0  0.005838\n",
      "16   50.000        0           0  0.005838\n",
      "17   25.000        0           0  0.005838\n",
      "18   50.000        0           0  0.005814\n",
      "19   50.000        0           0  0.005814\n",
      "20   15.000        0           0  1.000000\n",
      "21    1.700        1           1  0.005838\n",
      "22   10.000        1           1  0.999964\n",
      "23   10.000        1           1  0.056282\n",
      "24   10.000        1           1  0.999858\n",
      "25    2.000        1           1  0.008189\n",
      "26   10.000        1           1  0.999831\n",
      "28   10.000        1           1  0.028749\n",
      "48   50.000        0           0  0.999927\n",
      "52    9.400        1           1  0.620186\n",
      "53   50.000        0           0  0.999927\n",
      "54  100.000        0           0  0.008783\n",
      "55  100.000        0           0  0.013230\n",
      "56   17.600        0           0  0.013230\n",
      "57  100.000        0           0  0.013230\n",
      "58  100.000        0           0  0.019975\n",
      "59  100.000        0           0  0.008189\n",
      "60  100.000        0           0  0.009353\n",
      "61  100.000        0           0  0.011832\n",
      "62   25.000        0           0  0.419698\n",
      "63   50.000        0           0  0.011832\n",
      "64   50.000        0           0  0.028749\n",
      "65   50.000        0           0  0.028749\n",
      "66   50.000        0           0  0.048922\n",
      "67   50.000        0           0  0.008942\n",
      "68   50.000        0           0  0.008942\n",
      "69   18.500        0           0  0.058882\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV Performance\n",
    "print(pd.DataFrame(\n",
    "    {\"IC50\": y_data, \n",
    "     \"y_class\": y_class, \n",
    "     \"Prediction\": predict, \n",
    "     \"Proba\": predict_proba[:,1]})[\n",
    "    [\"IC50\", \"y_class\", \"Prediction\", \"Proba\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0]\n",
      " [ 0 36]]\n",
      "[['TP' 'FN']\n",
      " ['FP' 'TN']]\n"
     ]
    }
   ],
   "source": [
    "# Analyze train prediction performance\n",
    "best_model.fit(x_data, y_class)\n",
    "predict = best_model.predict(x_data)\n",
    "print(confusion_matrix(y_class, predict, labels=[1, 0]))\n",
    "print(np.array([[\"TP\", \"FN\"], [\"FP\", \"TN\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATS5p_sq</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MATS5m</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATSC6v</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATSC6v_sq</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MATS5p_cube</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MATS5m_exp2</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MATS5m_exp</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MATS5m_cube</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MATS5p_exp2</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MATS5p_exp</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MATS5p</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATSC0i_log2</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ATSC0i_log10</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ATSC0i_log</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  Importance\n",
       "0      MATS5p_sq       0.175\n",
       "1         MATS5m       0.150\n",
       "2         ATSC6v       0.125\n",
       "3      ATSC6v_sq       0.100\n",
       "4    MATS5p_cube       0.075\n",
       "5    MATS5m_exp2       0.075\n",
       "6     MATS5m_exp       0.075\n",
       "7    MATS5m_cube       0.075\n",
       "8    MATS5p_exp2       0.025\n",
       "9     MATS5p_exp       0.025\n",
       "10        MATS5p       0.025\n",
       "11   ATSC0i_log2       0.025\n",
       "12  ATSC0i_log10       0.025\n",
       "13    ATSC0i_log       0.025"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(x_data, y_class)\n",
    "feat_importance = best_model.feature_importances_\n",
    "best_features = [\n",
    "    (f, i) for i, f in sorted(zip(feat_importance, x_data.columns), \n",
    "                              reverse=True) if i != 0]\n",
    "feat_df = pd.DataFrame(best_features)\n",
    "feat_df.columns = [\"Feature\", \"Importance\"]\n",
    "feat_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptors Info\n",
    "http://www.talete.mi.it/products/dragon_molecular_descriptor_list.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
