{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Feature Importance for Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process steps:\n",
    "* Build full dataset with decoys and compounds\n",
    "* Build compound-only dataset\n",
    "* Preprocess categorical with one-hot-encoding\n",
    "* Find intersecting columns and filter compound-only to these\n",
    "* Add non-linear transformations to compound-only dataset\n",
    "* Create binary target with IC50 <= 10 as 1, else 0\n",
    "* Using compound-only df, fine-tune random forest with GridSearchCV (CV = count of positive class)\n",
    "* Extract feature importance and remove any with importance of 0\n",
    "* Create important features in full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skewtest\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from custom_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_transformations = [\"log\", \"log2\", \"log10\", \"cubert\", \n",
    "                         \"sqrt\", \"exp\", \"exp2\", \"cube\", \"sq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build full-dataset\n",
    "* Build compound-dataset\n",
    "* Preprocess data adding one-hot-encoded features for both\n",
    "* Find intersecting columns\n",
    "* Add non-linear transformations and drop na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Akt1_decoys_padel.csv....\n",
      "Adding AmpC_decoys_padel.csv....\n",
      "Adding cp3a4_decoys_padel.csv....\n",
      "Adding cxcr4_decoys_padel.csv....\n",
      "Adding gcr_decoys_padel.csv....\n",
      "Adding HIVpr_decoys_padel.csv....\n",
      "Adding HIVrt_decoys_padel.csv....\n",
      "Adding Kif11_decoys_padel.csv....\n",
      "Loading in compound dataset....\n",
      "Adding non-linear features to compound dataset....\n"
     ]
    }
   ],
   "source": [
    "# Load in full dataset\n",
    "full_x, full_y = load_full_dataset()\n",
    "# Preprocess variables\n",
    "full_x = preprocess_variables(full_x)\n",
    "# Extract list of available columns\n",
    "full_columns = full_x.columns\n",
    "print(\"Loading in compound dataset....\")\n",
    "# Read in compound dataset\n",
    "compound_x, compound_y = load_compound_dataset()\n",
    "# Preprocess\n",
    "compound_x = preprocess_variables(compound_x)\n",
    "# Find intersecting features\n",
    "avail_columns = compound_x.columns.intersection(full_columns)\n",
    "# Select features on subset\n",
    "x_data = compound_x.loc[:, avail_columns]\n",
    "y_data = compound_y.copy()\n",
    "print(\"Adding non-linear features to compound dataset....\")\n",
    "# Add all transformations on compound data\n",
    "for feature in x_data.columns[x_data.dtypes == 'float64']:\n",
    "    x_data = add_transformations(x_data, feature)\n",
    "# Drop any new columns with NaN due to improper transformation\n",
    "x_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "x_data.dropna(axis=1, inplace=True)\n",
    "assert not sum(x_data.isna().sum()), \"Unexpected nulls found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary variable\n",
    "y_class = np.squeeze([int(y_val <= 10) for y_val in y_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning random forest on compound dataset....\n",
      "{'min_samples_split': 2, 'n_estimators': 40, 'max_features': 'auto', 'criterion': 'entropy', 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "# How well does random forest predict potency?\n",
    "print(\"Tuning random forest on compound dataset....\")\n",
    "rf_model = RandomForestClassifier(random_state=0, \n",
    "                               class_weight={0: 1-np.mean(y_class), \n",
    "                                             1: np.mean(y_class)})\n",
    "params = {\"n_estimators\": [30, 40, 50],\n",
    "          \"max_depth\": [3, 4, 5],\n",
    "          \"min_samples_split\": [2, 3],\n",
    "         \"criterion\": [\"entropy\"],\n",
    "         \"max_features\": [\"auto\"]}\n",
    "grid = GridSearchCV(estimator=rf_model, param_grid=params, cv=5, n_jobs=3)\n",
    "\n",
    "grid.fit(x_data, y_class)\n",
    "print(grid.best_params_)\n",
    "best_rf_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  8]\n",
      " [ 4 32]]\n",
      "[['TP' 'FN']\n",
      " ['FP' 'TN']]\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV prediction performance\n",
    "predict = cross_val_predict(\n",
    "    best_rf_model, x_data, y_class, cv=sum(y_class), method=\"predict\")\n",
    "\n",
    "predict_proba = cross_val_predict(\n",
    "    best_rf_model, x_data, y_class, cv=sum(y_class), method=\"predict_proba\")\n",
    "\n",
    "print(confusion_matrix(y_class, predict, labels=[1, 0]))\n",
    "print(np.array([[\"TP\", \"FN\"], [\"FP\", \"TN\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning AdaBoost on compound dataset....\n",
      "{'learning_rate': 0.05, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "# How well does AdaBoost predict potency?\n",
    "print(\"Tuning AdaBoost on compound dataset....\")\n",
    "model = AdaBoostClassifier(random_state=0)\n",
    "params = {\"n_estimators\": [35, 40, 45],\n",
    "          \"learning_rate\": [0.05, 0.075]}\n",
    "grid = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=3, scoring=make_scorer(roc_auc_score))\n",
    "\n",
    "grid.fit(x_data, y_class)\n",
    "print(grid.best_params_)\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "best_model = AdaBoostClassifier(random_state=0, learning_rate=0.075, n_estimators=5)\n",
    "# Best model from other analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  4]\n",
      " [ 4 32]]\n",
      "[['TP' 'FN']\n",
      " ['FP' 'TN']]\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV prediction performance\n",
    "predict = cross_val_predict(\n",
    "    best_model, x_data, y_class, cv=sum(y_class), method=\"predict\")\n",
    "\n",
    "predict_proba = cross_val_predict(\n",
    "    best_model, x_data, y_class, cv=sum(y_class), method=\"predict_proba\")\n",
    "\n",
    "print(confusion_matrix(y_class, predict, labels=[1, 0]))\n",
    "print(np.array([[\"TP\", \"FN\"], [\"FP\", \"TN\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7626262626262625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_class, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       IC50  y_class  Prediction     Proba\n",
      "0     0.036        1           1  0.999236\n",
      "1    10.000        1           0  0.068899\n",
      "2    50.000        0           0  0.208487\n",
      "3    50.000        0           0  0.123817\n",
      "4    50.000        0           0  0.123817\n",
      "5     8.000        1           1  0.998017\n",
      "6    50.000        0           0  0.123817\n",
      "7    50.000        0           0  0.068899\n",
      "8    35.000        0           0  0.068899\n",
      "9    50.000        0           0  0.068899\n",
      "10   45.000        0           0  0.068899\n",
      "11   45.000        0           0  0.092583\n",
      "12   40.000        0           0  0.092583\n",
      "13   50.000        0           0  0.092583\n",
      "14   50.000        0           0  0.092583\n",
      "15   50.000        0           0  0.061057\n",
      "16   50.000        0           0  0.061057\n",
      "17   25.000        0           0  0.061057\n",
      "18   50.000        0           1  0.993514\n",
      "19   50.000        0           0  0.062513\n",
      "20   15.000        0           1  1.000000\n",
      "21    1.700        1           0  0.061057\n",
      "22   10.000        1           1  0.999997\n",
      "23   10.000        1           1  0.994620\n",
      "24   10.000        1           1  0.999998\n",
      "25    2.000        1           0  0.000204\n",
      "26   10.000        1           1  0.999228\n",
      "28   10.000        1           0  0.044869\n",
      "48   50.000        0           1  0.994620\n",
      "52    9.400        1           1  0.995130\n",
      "53   50.000        0           1  0.994620\n",
      "54  100.000        0           0  0.085768\n",
      "55  100.000        0           0  0.075591\n",
      "56   17.600        0           0  0.075591\n",
      "57  100.000        0           0  0.075591\n",
      "58  100.000        0           0  0.331780\n",
      "59  100.000        0           0  0.000204\n",
      "60  100.000        0           0  0.000342\n",
      "61  100.000        0           0  0.120808\n",
      "62   25.000        0           0  0.120808\n",
      "63   50.000        0           0  0.120808\n",
      "64   50.000        0           0  0.044869\n",
      "65   50.000        0           0  0.044869\n",
      "66   50.000        0           0  0.342370\n",
      "67   50.000        0           0  0.075591\n",
      "68   50.000        0           0  0.075591\n",
      "69   18.500        0           0  0.075591\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV Performance\n",
    "print(pd.DataFrame(\n",
    "    {\"IC50\": y_data, \n",
    "     \"y_class\": y_class, \n",
    "     \"Prediction\": predict, \n",
    "     \"Proba\": predict_proba[:,1]})[\n",
    "    [\"IC50\", \"y_class\", \"Prediction\", \"Proba\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0]\n",
      " [ 0 36]]\n",
      "[['TP' 'FN']\n",
      " ['FP' 'TN']]\n"
     ]
    }
   ],
   "source": [
    "# Analyze train prediction performance\n",
    "best_model.fit(x_data, y_class)\n",
    "predict = best_model.predict(x_data)\n",
    "print(confusion_matrix(y_class, predict, labels=[1, 0]))\n",
    "print(np.array([[\"TP\", \"FN\"], [\"FP\", \"TN\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATS5p_sq</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MATS5m</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATSC6v</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATSC6v_sq</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MATS5p_cube</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MATS5m_exp2</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MATS5m_exp</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MATS5m_cube</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MATS5p_exp2</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MATS5p_exp</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MATS5p</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATSC0i_log2</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ATSC0i_log10</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ATSC0i_log</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  Importance\n",
       "0      MATS5p_sq       0.175\n",
       "1         MATS5m       0.150\n",
       "2         ATSC6v       0.125\n",
       "3      ATSC6v_sq       0.100\n",
       "4    MATS5p_cube       0.075\n",
       "5    MATS5m_exp2       0.075\n",
       "6     MATS5m_exp       0.075\n",
       "7    MATS5m_cube       0.075\n",
       "8    MATS5p_exp2       0.025\n",
       "9     MATS5p_exp       0.025\n",
       "10        MATS5p       0.025\n",
       "11   ATSC0i_log2       0.025\n",
       "12  ATSC0i_log10       0.025\n",
       "13    ATSC0i_log       0.025"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(x_data, y_class)\n",
    "feat_importance = best_model.feature_importances_\n",
    "best_features = [\n",
    "    (f, i) for i, f in sorted(zip(feat_importance, x_data.columns), \n",
    "                              reverse=True) if i != 0]\n",
    "feat_df = pd.DataFrame(best_features)\n",
    "feat_df.columns = [\"Feature\", \"Importance\"]\n",
    "feat_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptors Info\n",
    "http://www.talete.mi.it/products/dragon_molecular_descriptor_list.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
